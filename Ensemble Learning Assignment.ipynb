{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ef4670",
   "metadata": {},
   "source": [
    "# Ensemble Learning Assignment\n",
    "- Implement various methods of ensemble learning in Scratch.\n",
    "1. Blending\n",
    "## Problem 1: Scratch implementation of blending\n",
    "- Give at least three examples of implementing blending from scratch and getting better accuracy than a single model. Better accuracy means smaller mean squared error (MSE) on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c48b0645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "house_data = pd.read_csv('train.csv')\n",
    "house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8f7bf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea    0\n",
       "YearBuilt    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this assignment we will use sales price as objective variable and grlivarea and yearbuilt as explanatory variable\n",
    "X = house_data[['GrLivArea','YearBuilt']] # select GrLivArea and YearBuilt as explanatory features\n",
    "y = house_data['SalePrice'] # select SalePrice as objective variable\n",
    "null_count = X.isnull().sum() # check dataset for null values\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a2c67b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values # convert to ndarray\n",
    "y = y.values # convert to ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d798749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into 80% training data and 20% validation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7d44b170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.95809883e-16 -3.46716567e-15]\n",
      "[-0.05060307  0.06069477]\n"
     ]
    }
   ],
   "source": [
    "# standardize/normalize the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train ) #assign standardized variables to X_train_scaled\n",
    "print(X_train.mean(axis=0)) \n",
    "X_test = scaler.transform(X_test)#assign standardized variables to X_test_scaled\n",
    "print(X_test.mean(axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cefc5734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "[0.88576695 0.9664846 ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.std(axis=0))\n",
    "print(X_test.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f5d142f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 1907504023.479166\n",
      "Random Forest MSE: 1679955268.6499934\n",
      "Blended MSE: 1565497454.835617\n"
     ]
    }
   ],
   "source": [
    "# 1st example\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "lr.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "rf_pred = rf.predict(X_test)\n",
    "blend_pred = 0.5*lr_pred + 0.5*rf_pred # calculate blend using average option\n",
    "#calculate mse for each model and blended model\n",
    "lr_mse = mean_squared_error(y_test, lr_pred)\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)\n",
    "blend_mse = mean_squared_error(y_test, blend_pred)\n",
    "\n",
    "print(\"Linear Regression MSE:\", lr_mse)\n",
    "print(\"Random Forest MSE:\", rf_mse)\n",
    "print(\"Blended MSE:\", blend_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef5ef01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors MSE: 1630278415.659452\n",
      "Decision Tree MSE: 2605845818.5871387\n",
      "Blended MSE: 1791167508.8567393\n"
     ]
    }
   ],
   "source": [
    "# 2nd example\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "knn.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "dt_pred = dt.predict(X_test)\n",
    "blend_pred = 0.5*knn_pred + 0.5*dt_pred\n",
    "knn_mse = mean_squared_error(y_test, knn_pred)\n",
    "dt_mse = mean_squared_error(y_test, dt_pred)\n",
    "blend_mse = mean_squared_error(y_test, blend_pred)\n",
    "print(\"K-Nearest Neighbors MSE:\", knn_mse)\n",
    "print(\"Decision Tree MSE:\", dt_mse)\n",
    "print(\"Blended MSE:\", blend_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d3c0ba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network MSE: 36710188886.42445\n",
      "Support Vector Machine MSE: 6554411131.862905\n",
      "Blended MSE: 15540676371.111324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\workspace\\python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3rd example\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "nn = MLPRegressor(random_state=42, max_iter=1000)\n",
    "svm = SVR(kernel='rbf')\n",
    "nn.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "nn_pred = nn.predict(X_test)\n",
    "svm_pred = svm.predict(X_test)\n",
    "blend_pred = 0.5*nn_pred + 0.5*svm_pred\n",
    "nn_mse = mean_squared_error(y_test, nn_pred)\n",
    "svm_mse = mean_squared_error(y_test, svm_pred)\n",
    "blend_mse = mean_squared_error(y_test, blend_pred)\n",
    "\n",
    "print(\"Neural Network MSE:\", nn_mse)\n",
    "print(\"Support Vector Machine MSE:\", svm_mse)\n",
    "print(\"Blended MSE:\", blend_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17eeb08",
   "metadata": {},
   "source": [
    "- From above results blending gives smaller MSE than single model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a8857",
   "metadata": {},
   "source": [
    "## Problem 2: Scratch Implementation of bagging\n",
    "- Please provide at least one example that implements bagging from scratch and improves accuracy over a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a9ccee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 2605845818.5871387\n"
     ]
    }
   ],
   "source": [
    "# building a single model decision tree regressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "dtr = DecisionTreeRegressor(random_state=42)\n",
    "dtr.fit(X_train, y_train)\n",
    "dtr_pred = dtr.predict(X_test)\n",
    "dtr_mse = mean_squared_error(y_test, dtr_pred)\n",
    "print(\"Decision Tree MSE:\", dtr_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51683f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a bagging model class\n",
    "class BaggingRegressor:\n",
    "    def __init__(self, n_subsets = 10):\n",
    "        self.n_subsets = n_subsets\n",
    "        self.models = []\n",
    "    def fit(self, X, y):\n",
    "        for i in range(self.n_subsets):\n",
    "            # new bootsrap sample for training data\n",
    "            subset = np.random.choice(X.shape[0], size=X.shape[0], replace = True)\n",
    "            X_sample = X[subset]\n",
    "            y_sample = y[subset]\n",
    "            #create a decisiontreeregressor and train it on the bootstrap sample\n",
    "            tree = DecisionTreeRegressor()\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            #add the trained decision tree regressor to the list of models\n",
    "            self.models.append(tree)\n",
    "    def predict(self, X):\n",
    "        #make predictions using each model and return the average\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        return np.mean(predictions, axis=0)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0a8c3324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging model MSE: 1732668374.9130228\n"
     ]
    }
   ],
   "source": [
    "# Create a bagging regressor with 10 subsets of data\n",
    "bagging = BaggingRegressor(n_subsets=10)\n",
    "# Train the bagging regressor on the training data\n",
    "bagging.fit(X_train, y_train)\n",
    "# predict the data\n",
    "y_pred = bagging.predict(X_test)\n",
    "# calculate the mean squared error of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Bagging model MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e37ec79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 2605845818.5871387\n",
      "Bagging model MSE: 1732668374.9130228\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree MSE:\", dtr_mse)\n",
    "print(\"Bagging model MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8076024",
   "metadata": {},
   "source": [
    "- As you can see from the above results bagging model has less MSE than single model hence its more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da391df1",
   "metadata": {},
   "source": [
    "## Problem 3: Scratch implementation of Stacking\n",
    "- Show at least one example that implements stacking from scratch and improves accuracy over a single model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d648d63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked model MSE:  1852207205.3103755\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "models = [\n",
    "    DecisionTreeRegressor(max_depth=3),\n",
    "    RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "]\n",
    "\n",
    "# Create an empty matrix for the meta-features\n",
    "meta_X_train = np.zeros((X_train.shape[0], len(models)))\n",
    "\n",
    "# Train the stage 0 models and create the meta-features\n",
    "for i, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    meta_X_train[:, i] = model.predict(X_train)\n",
    "\n",
    "# Train the stage 1 model on the meta-features\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_X_train, y_train)\n",
    "\n",
    "# Create an empty matrix for the test set meta-features\n",
    "meta_X_test = np.zeros((X_test.shape[0], len(models)))\n",
    "\n",
    "# Create the test set meta-features\n",
    "for i, model in enumerate(models):\n",
    "    meta_X_test[:, i] = model.predict(X_test)\n",
    "\n",
    "# Use the stage 1 model to make predictions on the test set meta-features\n",
    "y_pred = meta_model.predict(meta_X_test)\n",
    "\n",
    "# Evaluate the performance of the stacked model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('Stacked model MSE: ', mean_squared_error(y_test, y_pred, squared=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "874031d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class StackingRegressor:\n",
    "    def __init__(self, base_models, meta_model, n_folds):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [clone(model) for model in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        \n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "        blend_train = np.zeros((X.shape[0], len(self.base_models_)))\n",
    "\n",
    "        for i, model in enumerate(self.base_models_):\n",
    "            for train_index, val_index in kf.split(X):\n",
    "                X_train, y_train = X[train_index], y[train_index]\n",
    "                X_val, y_val = X[val_index], y[val_index]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                y_val_pred = model.predict(X_val)\n",
    "                blend_train[val_index, i] = y_val_pred\n",
    "\n",
    "        self.meta_model_.fit(blend_train, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        blend_test = np.zeros((X.shape[0], len(self.base_models_)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models_):\n",
    "            blend_test[:, i] = model.predict(X)\n",
    "\n",
    "        return self.meta_model_.predict(blend_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "852efd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# define base models and meta-model\n",
    "base_models = [\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    LinearRegression()\n",
    "]\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# instantiate and fit the stacking regressor\n",
    "stacking_reg = StackingRegressor(base_models=base_models, meta_model=meta_model, n_folds=2)\n",
    "stacking_reg.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = stacking_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5762df45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked model MSE:  1530048732.2503896\n"
     ]
    }
   ],
   "source": [
    "print('Stacked model MSE: ', mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a17fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
